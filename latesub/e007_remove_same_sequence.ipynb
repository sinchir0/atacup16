{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_NAME = \"e007_remove_same_sequence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import seaborn as sns\n",
    "import japanize_matplotlib\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    OUTPUT_DIR = f\"../saved_data/{NOTEBOOK_NAME}\"\n",
    "    SEED = 33\n",
    "    TARGET_COL = \"reserve\"\n",
    "\n",
    "\n",
    "os.makedirs(Config.OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log = pd.read_csv(\"../data/train_log.csv\")\n",
    "train_label = pd.read_csv(\"../data/train_label.csv\")\n",
    "\n",
    "test_log = pd.read_csv(\"../data/test_log.csv\")\n",
    "test_session = pd.read_csv(\"../data/test_session.csv\")\n",
    "\n",
    "yado = pd.read_csv(\"../data/yado.csv\")\n",
    "\n",
    "sample_submission = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "\n",
    "# # image_embeddings = pd.read_parquet(\"../data/image_embeddings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001149e9c73985425197104712478c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000e02747d749a52b7736dfa751e258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000f17ae2628237d78d3a38b009d3be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000174a6f7a569b84c5575760d2e9664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017e2a527901c9c41b1acef525d016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174695</th>\n",
       "      <td>fffee3199ef94b92283239cd5e3534fa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174696</th>\n",
       "      <td>ffff62c6bb49bc9c0fbcf08494a4869c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174697</th>\n",
       "      <td>ffff9a7dcc892875c7a8b821fa436228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174698</th>\n",
       "      <td>ffffb1d30300fe17f661941fd085b04b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174699</th>\n",
       "      <td>ffffe984aafd6127ce8e43e3ca40c79d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174700 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              session_id\n",
       "0       00001149e9c73985425197104712478c\n",
       "1       0000e02747d749a52b7736dfa751e258\n",
       "2       0000f17ae2628237d78d3a38b009d3be\n",
       "3       000174a6f7a569b84c5575760d2e9664\n",
       "4       00017e2a527901c9c41b1acef525d016\n",
       "...                                  ...\n",
       "174695  fffee3199ef94b92283239cd5e3534fa\n",
       "174696  ffff62c6bb49bc9c0fbcf08494a4869c\n",
       "174697  ffff9a7dcc892875c7a8b821fa436228\n",
       "174698  ffffb1d30300fe17f661941fd085b04b\n",
       "174699  ffffe984aafd6127ce8e43e3ca40c79d\n",
       "\n",
       "[174700 rows x 1 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\n",
    "    \"../saved_data/e039_make_data_add_next_all/train_candidate.parquet\"\n",
    ")\n",
    "\n",
    "test = pd.read_parquet(\n",
    "    \"../saved_data/e039_make_data_add_next_all/test_candidate.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2706026, 2)\n",
      "(4820206, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173861"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"session_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserveを付与する\n",
    "# 正解ラベルに含まれているレコードの index を配列で取得して\n",
    "target_index = pd.merge(\n",
    "    train.reset_index(), train_label, on=[\"session_id\", \"yad_no\"], how=\"inner\"\n",
    ")[\"index\"].values\n",
    "\n",
    "# 正解Indexに含まれている場合 1 / そうでないと 0 のラベルを作成\n",
    "train[\"reserve\"] = train.index.isin(target_index).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # debug\n",
    "# train = train.sample(10000, random_state=Config.SEED).reset_index(drop=True)\n",
    "# test = test.sample(10000, random_state=Config.SEED).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug用\n",
    "# train = train.sample(10000, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ひとつ前のlogのyad_idの値を取得\n",
    "# train[\"previous_1_yad_no\"] = train[\"logged_yad_no_list\"].apply(lambda x: x[-1])\n",
    "# test[\"previous_1_yad_no\"] = test[\"logged_yad_no_list\"].apply(lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (同じシーケンス, 候補宿)の組み合わせが複数ある場合、1つでも正例がある場合は1を、1つも正例がない場合は0を残す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id\n",
       "000007603d533d30453cc45d0f3d119f                 2395\n",
       "0000ca043ed437a1472c9d1d154eb49b                13535\n",
       "0000d4835cf113316fe447e2f80ba1c8                  123\n",
       "0000fcda1ae1b2f431e55a7075d1f500                 8475\n",
       "000104bdffaaad1a1e0a9ebacf585f33               96_898\n",
       "                                          ...        \n",
       "ffff2262d38abdeb247ebd591835dcc9                 8140\n",
       "ffff2360540745117193ecadcdc06538                 2121\n",
       "ffff7fb4617164b2604aaf51c40bf82d                 7183\n",
       "ffffcd5bc19d62cad5a3815c87818d83    12230_10619_12230\n",
       "fffffa7baf370083ebcdd98f26a7e31a           2439_11822\n",
       "Name: yad_no, Length: 288698, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 同じsession_idにおけるyad_noのリストを文字列として取得\n",
    "tmp = (\n",
    "    train_log\n",
    "    .groupby(\"session_id\")[\"yad_no\"]\n",
    "    .apply(list)\n",
    "    .apply(lambda x: '_'.join(map(str, x)))\n",
    ")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = (\n",
    "    train\n",
    "    .assign(logged_yad_no_list=train[\"session_id\"].map(tmp))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logged_yad_no_list</th>\n",
       "      <th>yad_no</th>\n",
       "      <th>reserve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1801</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>3656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>5158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>6698</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>7214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002218</th>\n",
       "      <td>9_8971</td>\n",
       "      <td>3230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002219</th>\n",
       "      <td>9_8971</td>\n",
       "      <td>4649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002220</th>\n",
       "      <td>9_8971</td>\n",
       "      <td>5553</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002221</th>\n",
       "      <td>9_8971</td>\n",
       "      <td>9904</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002222</th>\n",
       "      <td>9_8971</td>\n",
       "      <td>13677</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1002223 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        logged_yad_no_list  yad_no  reserve\n",
       "0                       10    1801        1\n",
       "1                      100    3656        0\n",
       "2                      100    5158        0\n",
       "3                      100    6698        0\n",
       "4                      100    7214        1\n",
       "...                    ...     ...      ...\n",
       "1002218             9_8971    3230        0\n",
       "1002219             9_8971    4649        0\n",
       "1002220             9_8971    5553        0\n",
       "1002221             9_8971    9904        0\n",
       "1002222             9_8971   13677        0\n",
       "\n",
       "[1002223 rows x 3 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = (\n",
    "    train\n",
    "    .groupby([\"logged_yad_no_list\", \"yad_no\"])[\"reserve\"]\n",
    "    .max()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logged_yad_no_list</th>\n",
       "      <th>yad_no</th>\n",
       "      <th>reserve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1801</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>3656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>5158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>6698</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>7214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002218</th>\n",
       "      <td>9_8971</td>\n",
       "      <td>3230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002219</th>\n",
       "      <td>9_8971</td>\n",
       "      <td>4649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002220</th>\n",
       "      <td>9_8971</td>\n",
       "      <td>5553</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002221</th>\n",
       "      <td>9_8971</td>\n",
       "      <td>9904</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002222</th>\n",
       "      <td>9_8971</td>\n",
       "      <td>13677</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1002223 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        logged_yad_no_list  yad_no  reserve\n",
       "0                       10    1801        1\n",
       "1                      100    3656        0\n",
       "2                      100    5158        0\n",
       "3                      100    6698        0\n",
       "4                      100    7214        1\n",
       "...                    ...     ...      ...\n",
       "1002218             9_8971    3230        0\n",
       "1002219             9_8971    4649        0\n",
       "1002220             9_8971    5553        0\n",
       "1002221             9_8971    9904        0\n",
       "1002222             9_8971   13677        0\n",
       "\n",
       "[1002223 rows x 3 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>yad_no</th>\n",
       "      <th>reserve</th>\n",
       "      <th>logged_yad_no_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000b45e91b9b92119cae54b5b54afbb3</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>6441_307_6441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0024b67ec2147ac898db802a632d9abe</td>\n",
       "      <td>4634</td>\n",
       "      <td>1</td>\n",
       "      <td>11800_4634_11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00653a79dc20ba6048f038fdda248e65</td>\n",
       "      <td>7272</td>\n",
       "      <td>1</td>\n",
       "      <td>7272_2650_10808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0092be6a47356678f14c8abad50ae698</td>\n",
       "      <td>8938</td>\n",
       "      <td>1</td>\n",
       "      <td>8938_2309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00978ea686bf3a109714273c55a070d9</td>\n",
       "      <td>12932</td>\n",
       "      <td>0</td>\n",
       "      <td>12932_7840_12932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180133</th>\n",
       "      <td>d83220067094c1a8949d6ca61c9d56fc</td>\n",
       "      <td>3329</td>\n",
       "      <td>0</td>\n",
       "      <td>2096_13803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180134</th>\n",
       "      <td>db0ff22a36105aee4628ca4ba22674ec</td>\n",
       "      <td>8589</td>\n",
       "      <td>0</td>\n",
       "      <td>1362_13803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180135</th>\n",
       "      <td>db0ff22a36105aee4628ca4ba22674ec</td>\n",
       "      <td>12464</td>\n",
       "      <td>0</td>\n",
       "      <td>1362_13803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180136</th>\n",
       "      <td>d8fe3981495b4e8c85f39e113390f489</td>\n",
       "      <td>9181</td>\n",
       "      <td>0</td>\n",
       "      <td>11336_13804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180137</th>\n",
       "      <td>d8fe3981495b4e8c85f39e113390f489</td>\n",
       "      <td>687</td>\n",
       "      <td>0</td>\n",
       "      <td>11336_13804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2180138 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               session_id  yad_no  reserve logged_yad_no_list\n",
       "0        000b45e91b9b92119cae54b5b54afbb3     307        1      6441_307_6441\n",
       "1        0024b67ec2147ac898db802a632d9abe    4634        1   11800_4634_11800\n",
       "2        00653a79dc20ba6048f038fdda248e65    7272        1    7272_2650_10808\n",
       "3        0092be6a47356678f14c8abad50ae698    8938        1          8938_2309\n",
       "4        00978ea686bf3a109714273c55a070d9   12932        0   12932_7840_12932\n",
       "...                                   ...     ...      ...                ...\n",
       "2180133  d83220067094c1a8949d6ca61c9d56fc    3329        0         2096_13803\n",
       "2180134  db0ff22a36105aee4628ca4ba22674ec    8589        0         1362_13803\n",
       "2180135  db0ff22a36105aee4628ca4ba22674ec   12464        0         1362_13803\n",
       "2180136  d8fe3981495b4e8c85f39e113390f489    9181        0        11336_13804\n",
       "2180137  d8fe3981495b4e8c85f39e113390f489     687        0        11336_13804\n",
       "\n",
       "[2180138 rows x 4 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = (\n",
    "    pd.merge(\n",
    "        train,\n",
    "        tmp,\n",
    "        on=[\"logged_yad_no_list\", \"yad_no\", \"reserve\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    .drop(columns=[\"reserve\"])\n",
    "    .drop_duplicates()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logged_yad_no_list</th>\n",
       "      <th>yad_no</th>\n",
       "      <th>reserve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1801</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>3656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>5158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>6698</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>7214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002218</th>\n",
       "      <td>9_8971</td>\n",
       "      <td>3230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002219</th>\n",
       "      <td>9_8971</td>\n",
       "      <td>4649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002220</th>\n",
       "      <td>9_8971</td>\n",
       "      <td>5553</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002221</th>\n",
       "      <td>9_8971</td>\n",
       "      <td>9904</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002222</th>\n",
       "      <td>9_8971</td>\n",
       "      <td>13677</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1002223 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        logged_yad_no_list  yad_no  reserve\n",
       "0                       10    1801        1\n",
       "1                      100    3656        0\n",
       "2                      100    5158        0\n",
       "3                      100    6698        0\n",
       "4                      100    7214        1\n",
       "...                    ...     ...      ...\n",
       "1002218             9_8971    3230        0\n",
       "1002219             9_8971    4649        0\n",
       "1002220             9_8971    5553        0\n",
       "1002221             9_8971    9904        0\n",
       "1002222             9_8971   13677        0\n",
       "\n",
       "[1002223 rows x 3 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainのlogged_yad_no_listが[2753, 2222]のデータを抜き出す\n",
    "train[train[\"logged_yad_no_list\"].apply(lambda x: x == [2753, 2222])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sessionの情報を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_session_length(\n",
    "    train: pd.DataFrame,\n",
    "    train_log: pd.DataFrame,\n",
    "    test: pd.DataFrame,\n",
    "    test_log: pd.DataFrame,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    sessionの長さを追加する\n",
    "    \"\"\"\n",
    "    train_session_id_cnt_dict = (\n",
    "        train_log.groupby(\"session_id\")[\"yad_no\"].count().to_dict()\n",
    "    )\n",
    "    test_session_id_cnt_dict = (\n",
    "        test_log.groupby(\"session_id\")[\"yad_no\"].count().to_dict()\n",
    "    )\n",
    "\n",
    "    train[\"session_length\"] = train[\"session_id\"].map(train_session_id_cnt_dict)\n",
    "    test[\"session_length\"] = test[\"session_id\"].map(test_session_id_cnt_dict)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "train, test = add_session_length(train, train_log, test, test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_session_yado_nunique(\n",
    "    train: pd.DataFrame,\n",
    "    train_log: pd.DataFrame,\n",
    "    test: pd.DataFrame,\n",
    "    test_log: pd.DataFrame,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    sessionの中で登場したyadoの数を追加する\n",
    "    \"\"\"\n",
    "    train_session_yado_cnt_dict = (\n",
    "        train_log.groupby(\"session_id\")[\"yad_no\"].nunique().to_dict()\n",
    "    )\n",
    "    test_session_yado_cnt_dict = (\n",
    "        test_log.groupby(\"session_id\")[\"yad_no\"].nunique().to_dict()\n",
    "    )\n",
    "\n",
    "    train[\"session_yado_nunique\"] = train[\"session_id\"].map(train_session_yado_cnt_dict)\n",
    "    test[\"session_yado_nunique\"] = test[\"session_id\"].map(test_session_yado_cnt_dict)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "train, test = add_session_yado_nunique(train, train_log, test, test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_session_yado_cnt(\n",
    "    train: pd.DataFrame,\n",
    "    train_log: pd.DataFrame,\n",
    "    test: pd.DataFrame,\n",
    "    test_log: pd.DataFrame,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    sessionとyadごとに、yad_noが登場した回数を数える\n",
    "    \"\"\"\n",
    "    train = train.copy()\n",
    "    train_log = train_log.copy()\n",
    "    test = test.copy()\n",
    "    test_log = test_log.copy()\n",
    "\n",
    "    train_session_yado_cnt = (\n",
    "        train_log.groupby([\"session_id\", \"yad_no\"])[\"yad_no\"]\n",
    "        .count()\n",
    "        .rename(\"session_yado_cnt\")\n",
    "    )\n",
    "    test_session_yado_cnt = (\n",
    "        test_log.groupby([\"session_id\", \"yad_no\"])[\"yad_no\"]\n",
    "        .count()\n",
    "        .rename(\"session_yado_cnt\")\n",
    "    )\n",
    "\n",
    "    train = train.merge(train_session_yado_cnt, on=[\"session_id\", \"yad_no\"], how=\"left\")\n",
    "    train[\"session_yado_cnt\"] = train[\"session_yado_cnt\"].fillna(0).astype(int)\n",
    "\n",
    "    test = test.merge(test_session_yado_cnt, on=[\"session_id\", \"yad_no\"], how=\"left\")\n",
    "    test[\"session_yado_cnt\"] = test[\"session_yado_cnt\"].fillna(0).astype(int)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "train, test = add_session_yado_cnt(train, train_log, test, test_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logの中で、宿の情報の統計値（平均、最大、最小、分散、中央値）をとる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_yad_statistic_from_log(\n",
    "    log_df: pd.DataFrame, session_df: pd.DataFrame, yado: pd.DataFrame\n",
    "):\n",
    "    log_df = log_df.copy()\n",
    "    session_df = session_df.copy()\n",
    "    yado = yado.copy()\n",
    "\n",
    "    log_with_yad = pd.merge(log_df, yado, on=\"yad_no\", how=\"left\")\n",
    "\n",
    "    use_cols = [\n",
    "        \"yad_type\",\n",
    "        \"total_room_cnt\",\n",
    "        \"wireless_lan_flg\",\n",
    "        \"onsen_flg\",\n",
    "        \"kd_stn_5min\",\n",
    "        \"kd_bch_5min\",\n",
    "        \"kd_slp_5min\",\n",
    "        \"kd_conv_walk_5min\",\n",
    "    ]\n",
    "\n",
    "    agg_ways = [\"mean\", \"max\", \"min\", \"std\", \"median\"]\n",
    "\n",
    "    for yad_col in use_cols:\n",
    "        agg_df = (\n",
    "            log_with_yad.groupby(\"session_id\")[yad_col]\n",
    "            .agg(agg_ways)\n",
    "            .add_prefix(f\"{yad_col}_\")\n",
    "        )\n",
    "        session_df = pd.merge(session_df, agg_df, on=\"session_id\", how=\"left\")\n",
    "\n",
    "    agg_col_name = [\n",
    "        f\"{yad_col}_{agg_way}\" for yad_col in use_cols for agg_way in agg_ways\n",
    "    ]\n",
    "\n",
    "    return session_df, agg_col_name\n",
    "\n",
    "\n",
    "train, yado_agg_col = add_yad_statistic_from_log(train_log, train, yado)\n",
    "test, _ = add_yad_statistic_from_log(test_log, test, yado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logの中で、wid_cd、ken_cd、lrg_cd、sml_cdのnuniqueをとる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_yad_area_nunique_from_log(\n",
    "    log_df: pd.DataFrame, session_df: pd.DataFrame, yado: pd.DataFrame\n",
    "):\n",
    "    log_df = log_df.copy()\n",
    "    session_df = session_df.copy()\n",
    "    yado = yado.copy()\n",
    "\n",
    "    log_with_yad = pd.merge(log_df, yado, on=\"yad_no\", how=\"left\")\n",
    "\n",
    "    use_cols = [\"wid_cd\", \"ken_cd\", \"lrg_cd\", \"sml_cd\"]\n",
    "\n",
    "    for area_col in use_cols:\n",
    "        agg_df = (\n",
    "            log_with_yad.groupby(\"session_id\")[area_col]\n",
    "            .nunique()\n",
    "            .rename(f\"{area_col}_nunique\")\n",
    "        )\n",
    "        session_df = session_df.merge(agg_df, on=\"session_id\", how=\"left\")\n",
    "\n",
    "    out_cols = [f\"{area_col}_nunique\" for area_col in use_cols]\n",
    "\n",
    "    return session_df, out_cols\n",
    "\n",
    "\n",
    "train, yad_area_nunique = add_yad_area_nunique_from_log(train_log, train, yado)\n",
    "test, _ = add_yad_area_nunique_from_log(train_log, test, yado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# session lengthが2以上の場合は、該当の宿がreverse_seq_no(max_seq_no - seq_no)を追加し、reverse_seq_noが偶数か奇数かのフラグを立てる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_reverse_seq_no(log_df: pd.DataFrame, session_df: pd.DataFrame):\n",
    "    log_df = log_df.copy()\n",
    "    session_df = session_df.copy()\n",
    "\n",
    "    # session_dfにseq_noを結合する\n",
    "    log_df_no_dup = log_df.drop_duplicates(subset=[\"session_id\", \"yad_no\"], keep=\"last\")\n",
    "    session_df = session_df.merge(\n",
    "        log_df_no_dup, on=[\"session_id\", \"yad_no\"], how=\"left\"\n",
    "    )\n",
    "\n",
    "    # sessionごとに最大のseq_noを結合する\n",
    "    log_max_seq_no = log_df.groupby(\"session_id\")[\"seq_no\"].max()\n",
    "    log_max_seq_no.name = \"max_seq_no\"\n",
    "    session_df = session_df.merge(log_max_seq_no, on=\"session_id\", how=\"left\")\n",
    "\n",
    "    # sessionの最大のseq_noの差分を取る(そのセッションが最後から何番目か？)\n",
    "    session_df[\"reverse_seq_no\"] = session_df[\"max_seq_no\"] - session_df[\"seq_no\"]\n",
    "    session_df[\"is_reverse_seq_no_odd\"] = session_df[\"reverse_seq_no\"] % 2\n",
    "\n",
    "    session_df.drop(columns=[\"seq_no\", \"max_seq_no\"], inplace=True)\n",
    "\n",
    "    return session_df\n",
    "\n",
    "\n",
    "train = add_reverse_seq_no(log_df=train_log, session_df=train)\n",
    "test = add_reverse_seq_no(log_df=test_log, session_df=test)\n",
    "# TODO: ここの処理が正しいか確認する\n",
    "# -> OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_seq_feat = [\"reverse_seq_no\", \"is_reverse_seq_no_odd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正解のyadoと1つ前のyadoの情報の追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 一番直近に見たyad_noを追加\n",
    "# train_previous_1_yad_no_dict = (\n",
    "#     train_log.groupby(\"session_id\")[\"yad_no\"].apply(lambda x: list(x)[-1]).to_dict()\n",
    "# )\n",
    "# test_previous_1_yad_no_dict = (\n",
    "#     test_log.groupby(\"session_id\")[\"yad_no\"].apply(lambda x: list(x)[-1]).to_dict()\n",
    "# )\n",
    "\n",
    "# train[\"previous_1_yad_no\"] = train[\"session_id\"].map(train_previous_1_yad_no_dict)\n",
    "# test[\"previous_1_yad_no\"] = test[\"session_id\"].map(test_previous_1_yad_no_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in tqdm(range(10)):\n",
    "    train_previous_n_yad_no_dict = (\n",
    "        train_log.groupby(\"session_id\")[\"yad_no\"]\n",
    "        .apply(lambda x: list(x)[-n] if len(x) >= n else 0)\n",
    "        .to_dict()\n",
    "    )\n",
    "    test_previous_n_yad_no_dict = (\n",
    "        test_log.groupby(\"session_id\")[\"yad_no\"]\n",
    "        .apply(lambda x: list(x)[-n] if len(x) >= n else 0)\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    train[f\"previous_{n}_yad_no\"] = train[\"session_id\"].map(\n",
    "        train_previous_n_yad_no_dict\n",
    "    )\n",
    "    test[f\"previous_{n}_yad_no\"] = test[\"session_id\"].map(test_previous_n_yad_no_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正解のyado情報の追加\n",
    "train = pd.merge(\n",
    "    train,\n",
    "    yado.add_prefix(\"now_\"),\n",
    "    left_on=\"yad_no\",\n",
    "    right_on=\"now_yad_no\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# 正解のyado情報の追加\n",
    "test = pd.merge(\n",
    "    test,\n",
    "    yado.add_prefix(\"now_\"),\n",
    "    left_on=\"yad_no\",\n",
    "    right_on=\"now_yad_no\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(10)):\n",
    "    # 前のyado情報の追加\n",
    "    train = pd.merge(\n",
    "        train,\n",
    "        yado.add_prefix(f\"previous_{i}_\"),\n",
    "        on=f\"previous_{i}_yad_no\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # 前のyado情報の追加\n",
    "    test = pd.merge(\n",
    "        test,\n",
    "        yado.add_prefix(f\"previous_{i}_\"),\n",
    "        on=f\"previous_{i}_yad_no\",\n",
    "        how=\"left\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_colの定義\n",
    "base_numeric_col = [\n",
    "    \"total_room_cnt\",\n",
    "    \"wireless_lan_flg\",\n",
    "    \"onsen_flg\",\n",
    "    \"kd_stn_5min\",\n",
    "    \"kd_bch_5min\",\n",
    "    \"kd_slp_5min\",\n",
    "    \"kd_conv_walk_5min\",\n",
    "]\n",
    "\n",
    "now_yado_numeric_col = [f\"now_{col}\" for col in base_numeric_col]\n",
    "previous_yado_numeric_cols = [\n",
    "    f\"previous_{i}_{col}\" for i in range(10) for col in base_numeric_col\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_colの定義\n",
    "yado_categorical_cols = [\n",
    "    \"yad_no\",\n",
    "    \"yad_type\",\n",
    "    \"wid_cd\",  # retrieveの条件が同じlrg_cdのデータの予定のため、今は学習に使わない\n",
    "    \"ken_cd\",  # retrieveの条件が同じlrg_cdのデータの予定のため、今は学習に使わない\n",
    "    \"lrg_cd\",  # retrieveの条件が同じlrg_cdのデータの予定のため、今は学習に使わない\n",
    "    \"sml_cd\",\n",
    "]\n",
    "\n",
    "now_yado_categorical_cols = [f\"now_{col}\" for col in yado_categorical_cols]\n",
    "previous_yado_categorical_cols = [\n",
    "    f\"previous_{i}_{col}\" for i in range(10) for col in yado_categorical_cols\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(previous_yado_categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 今の部屋と、前の部屋のwid_cd、ken_cd、lrg_cd、sml_cdが一緒かどうか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"same_wid_cd_now_previous_1\"] = train[\"now_wid_cd\"] == train[\"previous_1_wid_cd\"]\n",
    "train[\"same_ken_cd_now_previous_1\"] = train[\"now_ken_cd\"] == train[\"previous_1_ken_cd\"]\n",
    "train[\"same_lrg_cd_now_previous_1\"] = train[\"now_lrg_cd\"] == train[\"previous_1_lrg_cd\"]\n",
    "train[\"same_sml_cd_now_previous_1\"] = train[\"now_sml_cd\"] == train[\"previous_1_sml_cd\"]\n",
    "\n",
    "test[\"same_wid_cd_now_previous_1\"] = test[\"now_wid_cd\"] == test[\"previous_1_wid_cd\"]\n",
    "test[\"same_ken_cd_now_previous_1\"] = test[\"now_ken_cd\"] == test[\"previous_1_ken_cd\"]\n",
    "test[\"same_lrg_cd_now_previous_1\"] = test[\"now_lrg_cd\"] == test[\"previous_1_lrg_cd\"]\n",
    "test[\"same_sml_cd_now_previous_1\"] = test[\"now_sml_cd\"] == test[\"previous_1_sml_cd\"]\n",
    "\n",
    "same_area_feat = [\n",
    "    \"same_wid_cd_now_previous_1\",\n",
    "    \"same_ken_cd_now_previous_1\",\n",
    "    \"same_lrg_cd_now_previous_1\",\n",
    "    \"same_sml_cd_now_previous_1\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# foldごとに、rulebaseで推論した結果をrulebeased_predict_yadoとして追加する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_predicted_df = pd.read_pickle(\n",
    "#     \"../saved_data/e024_make_rulebased_feat/all_rulebased_predict_df_train.pkl\"\n",
    "# )\n",
    "\n",
    "# test_predicted_df = pd.read_pickle(\n",
    "#     \"../saved_data/e024_make_rulebased_feat/all_rulebased_predict_df_test.pkl\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.merge(train, train_predicted_df, on=\"session_id\", how=\"left\")\n",
    "# test = pd.merge(test, test_predicted_df, on=\"session_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rulebased_predict_feat = [\n",
    "#     \"rulebased_predict_0\",\n",
    "#     \"rulebased_predict_1\",\n",
    "#     \"rulebased_predict_2\",\n",
    "#     \"rulebased_predict_3\",\n",
    "#     \"rulebased_predict_4\",\n",
    "#     \"rulebased_predict_5\",\n",
    "#     \"rulebased_predict_6\",\n",
    "#     \"rulebased_predict_7\",\n",
    "#     \"rulebased_predict_8\",\n",
    "#     \"rulebased_predict_9\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     train[f\"same_rulebased_predict_{i}\"] = (\n",
    "#         train[\"yad_no\"] == train[f\"rulebased_predict_{i}\"]\n",
    "#     )\n",
    "#     test[f\"same_rulebased_predict_{i}\"] = (\n",
    "#         test[\"yad_no\"] == test[f\"rulebased_predict_{i}\"]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same_rulebased_predict_feat = [f\"same_rulebased_predict_{i}\" for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ型の変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = (\n",
    "    now_yado_categorical_cols\n",
    "    + previous_yado_categorical_cols\n",
    "    # + rulebased_predict_feat\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    train[col] = train[col].astype(\"category\")\n",
    "    test[col] = test[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cross Validationの際に用いるfold(分割する際のグループ番号)を追加\n",
    "# FOLD_NUM = 5\n",
    "\n",
    "# # skf = StratifiedKFold(n_splits=FOLD_NUM, shuffle=True, random_state=42)\n",
    "# # for fold, (_, v_idx) in enumerate(\n",
    "# #     skf.split(train, pd.cut(train[\"reserve\"], bins=3, labels=[\"0\", \"0.5\", \"1\"]))\n",
    "# # ):\n",
    "# #     train.loc[v_idx, \"fold\"] = fold\n",
    "\n",
    "# # TODO: yをsession_lengthにして試してみる\n",
    "# # sgkf = StratifiedGroupKFold(n_splits=FOLD_NUM, shuffle=True, random_state=Config.SEED)\n",
    "# # for fold, (_, v_idx) in enumerate(\n",
    "# #     sgkf.split(\n",
    "# #         X=train,\n",
    "# #         y=train[\"reserve\"],\n",
    "# #         groups=train[\"session_id\"],\n",
    "# #     )\n",
    "# # ):\n",
    "# #     train.loc[v_idx, \"fold\"] = fold\n",
    "\n",
    "# gkf = GroupKFold(n_splits=FOLD_NUM)\n",
    "# for fold, (_, v_idx) in enumerate(\n",
    "#     gkf.split(\n",
    "#         X=train,\n",
    "#         groups=train[\"session_id\"],\n",
    "#     )\n",
    "# ):\n",
    "#     train.loc[v_idx, \"fold\"] = fold\n",
    "\n",
    "# train[\"fold\"] = train[\"fold\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e016にて、データ作成時にfoldを利用するように変更\n",
    "with open(\n",
    "    \"../saved_data/e016_make_train_popular_base/session_id_fold_dict.pkl\", \"rb\"\n",
    ") as f:\n",
    "    session_id_fold_dict = pickle.load(f)\n",
    "\n",
    "train[\"fold\"] = train[\"session_id\"].map(session_id_fold_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_NUM = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby(\"fold\")[\"reserve\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 人気の宿情報、つまり予約された回数をfoldごとに付与する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id_fold_df = train[[\"session_id\", \"fold\"]].drop_duplicates()\n",
    "session_id_fold_dict = dict(\n",
    "    zip(session_id_fold_df[\"session_id\"], session_id_fold_df[\"fold\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_popular_per_fold(\n",
    "    train: pd.DataFrame,\n",
    "    train_label: pd.DataFrame,\n",
    "    test: pd.DataFrame,\n",
    "    n_fold: int = FOLD_NUM,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    foldごとに、宿が予約された回数を計算する\n",
    "    NOTE: 人気情報を付与して0.42ぐらいかなかったら何か間違っていそう\n",
    "    \"\"\"\n",
    "    train_label_copy = train_label.copy()\n",
    "\n",
    "    # train_labelに対して、trainを用いてsession_idごとのfoldを付与\n",
    "    session_id_fold_df = train[[\"session_id\", \"fold\"]].drop_duplicates()\n",
    "    session_id_fold_dict = dict(\n",
    "        zip(session_id_fold_df[\"session_id\"], session_id_fold_df[\"fold\"])\n",
    "    )\n",
    "\n",
    "    # その後、train_labelを用いて、foldごとにreserveの合計を計算\n",
    "    train_label_copy[\"fold\"] = train_label_copy[\"session_id\"].map(session_id_fold_dict)\n",
    "\n",
    "    # 学習データへの人気宿情報の付与\n",
    "    for fold in range(n_fold):\n",
    "        train_out_of_fold_df = train_label_copy[train_label_copy[\"fold\"] != fold]\n",
    "\n",
    "        train_yad_no_cnt_per_fold_dict = (\n",
    "            train_out_of_fold_df.groupby(\"yad_no\")[\"yad_no\"].count()\n",
    "            / train_out_of_fold_df.shape[0]\n",
    "        ).to_dict()\n",
    "        train.loc[train[\"fold\"] == fold, \"popular_yado_rate_per_fold\"] = train.loc[\n",
    "            train[\"fold\"] == fold, \"yad_no\"\n",
    "        ].map(train_yad_no_cnt_per_fold_dict)\n",
    "\n",
    "    # テストデータへの人気宿情報の付与\n",
    "    test_yad_no_cnt_per_fold_dict = (\n",
    "        train_label_copy.groupby(\"yad_no\")[\"yad_no\"].count() / train_label_copy.shape[0]\n",
    "    ).to_dict()\n",
    "    test[\"popular_yado_rate_per_fold\"] = test[\"yad_no\"].map(\n",
    "        test_yad_no_cnt_per_fold_dict\n",
    "    )\n",
    "\n",
    "    # 学習・テスト共に、1度も登場しなかった宿は予約回数が0回となるため、0に置換\n",
    "    train[\"popular_yado_rate_per_fold\"] = train[\"popular_yado_rate_per_fold\"].fillna(0)\n",
    "    test[\"popular_yado_rate_per_fold\"] = test[\"popular_yado_rate_per_fold\"].fillna(0)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "train, test = add_popular_per_fold(train, train_label, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 共起の情報を追加する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kyouki_df_train = pd.read_pickle(\n",
    "    f\"../saved_data/e033_make_feat_kyouki/kyouki_df_train.pkl\"\n",
    ")\n",
    "kyouki_df_test = pd.read_pickle(\n",
    "    f\"../saved_data/e033_make_feat_kyouki/kyouki_df_test.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(\n",
    "    kyouki_df_train,\n",
    "    left_on=[\"fold\", \"previous_1_yad_no\"],\n",
    "    right_on=[\"fold\", \"latest_yad_no\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "test = test.merge(\n",
    "    kyouki_df_test,\n",
    "    left_on=\"previous_1_yad_no\",\n",
    "    right_on=\"latest_yad_no\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kyouki_feat = [f\"kyouki_arr_reduced_{col}\" for col in range(100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# アソシエーションルールを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_co_visit_matrix = pd.read_parquet(\n",
    "    f\"../saved_data/e035_make_associ/train_co_visit_matrix.pkl\"\n",
    ")\n",
    "test_co_visit_matrix = pd.read_parquet(\n",
    "    f\"../saved_data/e035_make_associ/test_co_visit_matrix.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_co_visit_matrix.rename(\n",
    "    columns={\"latest_yad_no\": \"previous_1_yad_no\"}, inplace=True\n",
    ")\n",
    "test_co_visit_matrix.rename(\n",
    "    columns={\"latest_yad_no\": \"previous_1_yad_no\"}, inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(\n",
    "    train_co_visit_matrix,\n",
    "    on=[\"previous_1_yad_no\", \"yad_no\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "test = test.merge(\n",
    "    test_co_visit_matrix,\n",
    "    on=[\"previous_1_yad_no\", \"yad_no\"],\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "associ_feat = [\"co_visit_count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  latest_yad_noと現在のyad_noで共起した回数を追加する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kyouki_df_cnt_train = pd.read_pickle(\n",
    "    \"../saved_data/e039_make_feat_kyouki_by_one_col/kyouki_df_cnt_train.pkl\"\n",
    ")\n",
    "\n",
    "kyouki_df_cnt_test = pd.read_pickle(\n",
    "    \"../saved_data/e039_make_feat_kyouki_by_one_col/kyouki_df_cnt_test.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kyouki_df_cnt_train = kyouki_df_cnt_train.rename(\n",
    "    columns={\"latest_yad_no\": \"previous_1_yad_no\", \"count\": \"last_label_count\"}\n",
    ")\n",
    "\n",
    "kyouki_df_cnt_test = kyouki_df_cnt_test.rename(\n",
    "    columns={\"latest_yad_no\": \"previous_1_yad_no\", \"count\": \"last_label_count\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(\n",
    "    kyouki_df_cnt_train,\n",
    "    on=[\"fold\", \"previous_1_yad_no\", \"yad_no\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "test = test.merge(\n",
    "    kyouki_df_cnt_test,\n",
    "    on=[\"previous_1_yad_no\", \"yad_no\"],\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_label_count_feat = [\"last_label_count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習とテストに使うデータを保存する\n",
    "train.to_pickle(f\"{Config.OUTPUT_DIR}/{NOTEBOOK_NAME}_train.pkl\")\n",
    "\n",
    "test.to_pickle(f\"{Config.OUTPUT_DIR}/{NOTEBOOK_NAME}_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session系の特徴量\n",
    "session_numeric_col = [\n",
    "    \"session_length\",\n",
    "    \"session_yado_nunique\",\n",
    "    \"session_yado_cnt\",\n",
    "]\n",
    "\n",
    "per_fold_col = [\"popular_yado_rate_per_fold\"]\n",
    "\n",
    "numeric_cols = (\n",
    "    now_yado_numeric_col\n",
    "    + previous_yado_numeric_cols\n",
    "    + session_numeric_col\n",
    "    + per_fold_col\n",
    "    + same_area_feat  # 同じエリアかどうか\n",
    "    + yado_agg_col  # yadoの統計量\n",
    "    + yad_area_nunique  # areaの統計量\n",
    "    + reverse_seq_feat  # 逆順の特徴量\n",
    "    + kyouki_feat  # 共起特徴量\n",
    "    + associ_feat  # アソシエーションルールの特徴量\n",
    "    + last_label_count_feat  # 前回のラベルの数\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_col = numeric_cols + categorical_cols\n",
    "len(use_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBMで用いるパラメーターを指定\n",
    "# ref: https://lightgbm.readthedocs.io/en/v3.3.5/Parameters.html\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"max_depth\": -1,\n",
    "    # \"min_data_in_leaf\": 100, # 1つの葉に入る最小のデータ数\n",
    "    \"num_leaves\": 24,  # 2**max_depthより少し小さめにすると過学習を防げる\n",
    "    \"learning_rate\": 0.05,  # 1回のiterationで学習を進める割合、大きいと学習が早く終わる。小さいと学習は長いが高精度になりやすい。\n",
    "    \"bagging_freq\": 5,  # 指定した回数ごとにbaggingを行う\n",
    "    \"feature_fraction\": 0.9,  # 1回のiterationで利用する特徴量(列方向)の割合\n",
    "    \"bagging_fraction\": 0.8,  # 1回のiterationで利用するデータ(行方向)の割合\n",
    "    \"verbose\": -1,  # 出力するログレベルの変更、0はError(Warning)以上を表示\n",
    "    \"seed\": 42,  # ランダムシードの固定\n",
    "    \"lambda_l1\": 0.4,\n",
    "    \"lambda_l2\": 0.4,\n",
    "    \"importance_type\": \"gain\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     # 目的関数. これの意味で最小となるようなパラメータを探します.\n",
    "#     \"objective\": \"binary\",\n",
    "#     # 木の最大数\n",
    "#     \"n_estimators\": 10000,\n",
    "#     # 学習率. 小さいほどなめらかな決定境界が作られて性能向上に繋がる場合が多いです、\n",
    "#     # がそれだけ木を作るため学習に時間がかかります\n",
    "#     # 今回設定している 0.3 は比較的大きめの設定です\n",
    "#     \"learning_rate\": 0.3,\n",
    "#     # 特徴重要度計算のロジック(後述)\n",
    "#     \"importance_type\": \"gain\",\n",
    "#     \"random_state\": 510,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rmse(y_true, y_pred):\n",
    "#     return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データ全体に対する推論結果を保存するobjectを作成\n",
    "oof = np.zeros((len(train)))\n",
    "\n",
    "# テストデータに対する推論、特徴量重要度(後述)を計算するために、モデルを保存するobjectを作成\n",
    "models = []\n",
    "\n",
    "# Cross Validationによる学習の実施\n",
    "for fold in range(FOLD_NUM):\n",
    "    print(f\"Start fold {fold}\")\n",
    "\n",
    "    # foldごとにtrainとvalidに分ける\n",
    "    train_fold = train[train[\"fold\"] != fold]\n",
    "    valid_fold = train[train[\"fold\"] == fold]\n",
    "\n",
    "    # X(説明変数)とy(目的変数)に分ける\n",
    "    X_train = train_fold.drop(Config.TARGET_COL, axis=1)\n",
    "    X_valid = valid_fold.drop(Config.TARGET_COL, axis=1)\n",
    "    y_train = train_fold[[Config.TARGET_COL]]\n",
    "    y_valid = valid_fold[[Config.TARGET_COL]]\n",
    "\n",
    "    # 利用する説明変数に限定する\n",
    "    X_train = X_train[use_col]\n",
    "    X_valid = X_valid[use_col]\n",
    "\n",
    "    # LightGBMが認識可能な形にデータセットを変換\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
    "\n",
    "    # モデルの学習\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        num_boost_round=2000,  # 学習のiteration回数\n",
    "        valid_sets=[lgb_train, lgb_eval],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=100),\n",
    "            lgb.log_evaluation(100),\n",
    "        ],  # Early stopingの回数、binary_loglossが改善しないiterationが100回続いたら学習を止める\n",
    "    )\n",
    "\n",
    "    # モデルを保存\n",
    "    models.append(model)\n",
    "\n",
    "    # validデータに対する推論\n",
    "    y_valid_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "\n",
    "    # validデータに対する推論の性能を計算\n",
    "    # score = rmse(y_valid, y_valid_pred)\n",
    "    score = roc_auc_score(y_valid, y_valid_pred)\n",
    "\n",
    "    print(f\"fold {fold} Score: {score}\")\n",
    "\n",
    "    # oofに推論結果を保存\n",
    "    valid_idx = X_valid.index\n",
    "    oof[valid_idx] = y_valid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{Config.OUTPUT_DIR}/{NOTEBOOK_NAME}_models.pkl\", \"wb\") as f:\n",
    "    pickle.dump(models, f)\n",
    "\n",
    "with open(f\"{Config.OUTPUT_DIR}/{NOTEBOOK_NAME}_oof.pkl\", \"wb\") as f:\n",
    "    pickle.dump(oof, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{Config.OUTPUT_DIR}/{NOTEBOOK_NAME}_models.pkl\", \"rb\") as f:\n",
    "    models = pickle.load(f)\n",
    "\n",
    "with open(f\"{Config.OUTPUT_DIR}/{NOTEBOOK_NAME}_oof.pkl\", \"rb\") as f:\n",
    "    oof = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_score = rmse(train[Config.TARGET_COL][oof != 0], oof[oof != 0])\n",
    "oof_score = roc_auc_score(train[Config.TARGET_COL][oof != 0], oof[oof != 0])\n",
    "oof_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"oof_pred\"] = oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainをoofが0でないものだけに絞る\n",
    "def get_oof_pred_df(train: pd.DataFrame, oof: np.ndarray) -> pd.DataFrame:\n",
    "    train_for_calc_mapk = train.copy()\n",
    "    train_for_calc_mapk[\"oof\"] = oof\n",
    "    train_for_calc_mapk = train_for_calc_mapk[train_for_calc_mapk[\"oof\"] != 0]\n",
    "\n",
    "    # 推論順にsession_idとyad_noを並べる\n",
    "    oof_pred_yad = (\n",
    "        train_for_calc_mapk.sort_values([\"session_id\", \"oof\"], ascending=False)\n",
    "        .groupby(\"session_id\")[\"yad_no\"]\n",
    "        .apply(list)\n",
    "    ).to_dict()\n",
    "\n",
    "    # train_labelをoofの計算用に用意\n",
    "    train_label_for_calc_oof = train_label.copy()\n",
    "\n",
    "    # train_for_calc_mapkに付与\n",
    "    train_label_for_calc_oof[\"pred_yad_no_list\"] = train_label_for_calc_oof[\n",
    "        \"session_id\"\n",
    "    ].map(oof_pred_yad)\n",
    "\n",
    "    # oofが計算されていないsession_idは削除\n",
    "    train_label_for_calc_oof = train_label_for_calc_oof[\n",
    "        train_label_for_calc_oof[\"pred_yad_no_list\"].notnull()\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    # 上位10件に限定\n",
    "    train_label_for_calc_oof[\"pred_yad_no_list_top10\"] = train_label_for_calc_oof[\n",
    "        \"pred_yad_no_list\"\n",
    "    ].apply(lambda x: x[:10])\n",
    "\n",
    "    # listをpd.Seriesに変換\n",
    "    oof_pred_df = train_label_for_calc_oof.set_index(\"session_id\")[\n",
    "        \"pred_yad_no_list_top10\"\n",
    "    ].apply(pd.Series)\n",
    "    oof_pred_df = oof_pred_df.rename(columns=lambda x: \"predict_\" + str(x))\n",
    "\n",
    "    # Nullの箇所はyad_no=0で保管し、全ての値をintに変換する\n",
    "    # TODO: 埋めるのは0で本当に良いのか考える\n",
    "    oof_pred_df = oof_pred_df.fillna(0).astype(int)\n",
    "\n",
    "    return oof_pred_df\n",
    "\n",
    "\n",
    "oof_pred_df = get_oof_pred_df(train, oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label[train_label[\"session_id\"].isin(oof_pred_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k for a single actual value.\n",
    "\n",
    "    Parameters:\n",
    "    actual : int\n",
    "        The actual value that is to be predicted\n",
    "    predicted : list\n",
    "        A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        The average precision at k\n",
    "    \"\"\"\n",
    "    if actual in predicted[:k]:\n",
    "        return 1.0 / (predicted[:k].index(actual) + 1)\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k for lists of actual values and predicted values.\n",
    "\n",
    "    Parameters:\n",
    "    actual : list\n",
    "        A list of actual values that are to be predicted\n",
    "    predicted : list\n",
    "        A list of lists of predicted elements (order does matter in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        The mean average precision at k\n",
    "    \"\"\"\n",
    "    return sum(apk(a, p, k) for a, p in zip(actual, predicted)) / len(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPK (k=10) として計算\n",
    "sorted_train_label = (\n",
    "    train_label[train_label[\"session_id\"].isin(oof_pred_df.index)]\n",
    "    .sort_values(\"session_id\")[\"yad_no\"]\n",
    "    .values\n",
    ")\n",
    "\n",
    "assert len(sorted_train_label) == len(oof_pred_df)\n",
    "\n",
    "oof_mapk_score = mapk(\n",
    "    actual=sorted_train_label,\n",
    "    predicted=oof_pred_df.sort_index().values.tolist(),\n",
    "    k=10,\n",
    ")\n",
    "oof_mapk_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold, model in enumerate(models):\n",
    "    _df = pd.DataFrame()\n",
    "    _df[f\"fold_{fold}\"] = model.feature_importance(importance_type=\"gain\")\n",
    "    _df = _df.T\n",
    "    _df.columns = use_col\n",
    "    feature_importance_df = pd.concat([feature_importance_df, _df], axis=0)\n",
    "order = _df.mean().sort_values(ascending=False).index.tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(max(6, len(order) * 0.4), len(order) * 0.5))\n",
    "sns.boxplot(\n",
    "    data=feature_importance_df, orient=\"h\", order=order, ax=ax, palette=\"viridis\"\n",
    ")\n",
    "ax.grid()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testに対する推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k 個のモデルの予測を作成. shape = (5, N_test,).\n",
    "pred = np.array([model.predict(test[use_col]) for model in models])\n",
    "\n",
    "# k 個のモデルの予測値の平均 shape = (N_test,).\n",
    "pred = np.mean(pred, axis=0)  # axis=0 なので shape の `k` が潰れる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "vmax = 0.02\n",
    "# bins = np.linspace(0, 1, 0.1)\n",
    "ax.hist(pred, density=True, alpha=0.5, label=\"Test\")\n",
    "ax.hist(oof, density=True, alpha=0.5, label=\"OutOfFold\")\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "ax.set_title(\"テストと学習時の予測傾向差分\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"pred\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP10に並び替え\n",
    "# session_idごとにpredが高いyadoのlistを取得\n",
    "pred_yad = (\n",
    "    test.sort_values([\"session_id\", \"pred\"], ascending=False)\n",
    "    .groupby(\"session_id\")[\"yad_no\"]\n",
    "    .apply(list)\n",
    ").to_dict()\n",
    "\n",
    "test_session[\"pred_yad_no_list\"] = test_session[\"session_id\"].map(pred_yad)\n",
    "\n",
    "# test_sessionのpred_yad_no_listがNaNの場合は、[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]で埋める\n",
    "test_session[\"pred_yad_no_list\"] = test_session[\"pred_yad_no_list\"].apply(\n",
    "    lambda x: x if isinstance(x, list) else [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    ")\n",
    "\n",
    "# 上位10件に限定\n",
    "test_session[\"pred_yad_no_list_top10\"] = test_session[\"pred_yad_no_list\"].apply(\n",
    "    lambda x: x[:10]\n",
    ")\n",
    "\n",
    "# listをpd.Seriesに変換\n",
    "pred_yad_df = test_session[\"pred_yad_no_list_top10\"].apply(pd.Series)\n",
    "pred_yad_df = pred_yad_df.rename(columns=lambda x: \"predict_\" + str(x))\n",
    "\n",
    "print(pred_yad_df.isnull().sum())\n",
    "\n",
    "# Nullの箇所はyad_no=10095(一番人気)で保管し、全ての値をintに変換する\n",
    "# NOTE: 保管するのは本当に10095で良いのか考える\n",
    "# pred_yad_df = pred_yad_df.fillna(10095).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pred_yad_df.shape[0] == sample_submission.shape[0]\n",
    "assert list(pred_yad_df.columns) == list(sample_submission.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_yad_df.to_csv(\n",
    "    f\"../sub/{NOTEBOOK_NAME}_auc{oof_score:.4f}_mapk{oof_mapk_score:.4f}_with_null.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_yad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"../sub/{NOTEBOOK_NAME}_auc{oof_score:.4f}_mapk{oof_mapk_score:.4f}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 人気の情報を入れて、CVが改善しているのにtestのスコアが改善しないのはおかしいため、原因を調べる"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

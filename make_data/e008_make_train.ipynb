{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_NAME = \"e008_make_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import japanize_matplotlib\n",
    "\n",
    "from contextlib import contextmanager\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import shutil\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# ref: Kaggleコード遺産 https://qiita.com/kaggle_grandmaster-arai-san/items/d59b2fb7142ec7e270a5 \n",
    "class Timer:\n",
    "    def __init__(self, logger=None, format_str=\"{:.3f}[s]\", prefix=None, suffix=None, sep=\" \"):\n",
    "\n",
    "        if prefix: format_str = str(prefix) + sep + format_str\n",
    "        if suffix: format_str = format_str + sep + str(suffix)\n",
    "        self.format_str = format_str\n",
    "        self.logger = logger\n",
    "        self.start = None\n",
    "        self.end = None\n",
    "\n",
    "    @property\n",
    "    def duration(self):\n",
    "        if self.end is None:\n",
    "            return 0\n",
    "        return self.end - self.start\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.end = time()\n",
    "        out_str = self.format_str.format(self.duration)\n",
    "        if self.logger:\n",
    "            self.logger.info(out_str)\n",
    "        else:\n",
    "            print(out_str)\n",
    "\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# 再現性確保!\n",
    "seed_everything(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"../data\"\n",
    "OUTPUT_DIR = f\"../saved_data/{NOTEBOOK_NAME}\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習用のログデータと正解ラベル\n",
    "train_log = pd.read_csv(os.path.join(INPUT_DIR, \"train_log.csv\"))\n",
    "train_label = pd.read_csv(os.path.join(INPUT_DIR, \"train_label.csv\"))\n",
    "\n",
    "# 宿のデータ\n",
    "yado = pd.read_csv(os.path.join(INPUT_DIR, \"yado.csv\"))\n",
    "\n",
    "# テスト期間のログデータ\n",
    "test_log = pd.read_csv(os.path.join(INPUT_DIR, \"test_log.csv\"))\n",
    "\n",
    "sample_submission = pd.read_csv(os.path.join(INPUT_DIR, \"sample_submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_log_df = pd.concat([train_log, test_log], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_session_yad_df(input_df: pd.DataFrame):\n",
    "    \"\"\"input_df には train_log / test_log のいずれかが来ることを想定している\"\"\"\n",
    "    N = 10\n",
    "    sessions = input_df[\"session_id\"].unique()\n",
    "    out_df = pd.DataFrame(\n",
    "        {\n",
    "            \"session_id\": [x for s in sessions for x in [s] * N],\n",
    "            \"yad_no\": yado[\"yad_no\"].sample(n=N * len(sessions), replace=True).values,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ランダムに付け加えたもの以外・同一ログに出現する宿を候補にいれる\n",
    "    out_df = pd.concat([out_df, input_df[[\"session_id\", \"yad_no\"]]], ignore_index=True)\n",
    "\n",
    "    # 重複は意味がないので消します。\n",
    "    out_df = out_df.drop_duplicates()\n",
    "\n",
    "    # 見た目を揃えるために session / yad の順番でソートをします\n",
    "    out_df = out_df.sort_values([\"session_id\", \"yad_no\"]).reset_index(drop=True)\n",
    "\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_session_yad = create_session_yad_df(input_df=train_log)\n",
    "\n",
    "# 予測の際には session ごとに yado に対しての予約確率を出さなくてはなりませんから、同じように session - yado の組を作ります。\n",
    "# ただし学習時と同じような組で良いか? は議論が必要かもしれません. (ここに現れない宿は予測対象に絶対入らないため)\n",
    "test_session_yad = create_session_yad_df(input_df=test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正解ラベル train_label_df の組み合わせを付与\n",
    "_df = pd.concat([train_label, train_session_yad], ignore_index=True)\n",
    "\n",
    "# 重複を削除して\n",
    "_df = _df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# 正解ラベルに含まれているレコードの index を配列で取得して\n",
    "target_index = pd.merge(\n",
    "    _df.reset_index(), train_label, on=[\"session_id\", \"yad_no\"], how=\"inner\"\n",
    ")[\"index\"].values\n",
    "\n",
    "# 正解Indexに含まれている場合 1 / そうでないと 0 のラベルを作成\n",
    "_df[\"reserve\"] = _df.index.isin(target_index).astype(int)\n",
    "\n",
    "# 見た目を揃えるために session / yad でソートしておく\n",
    "_df = _df.sort_values([\"session_id\", \"yad_no\"]).reset_index(drop=True)\n",
    "\n",
    "_df.head(21)\n",
    "\n",
    "train_session_yad = _df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testデータへの後処理\n",
    "def remove_last_yad_id(session_yad_df):\n",
    "    # セッション中一番最後の宿の組を作成\n",
    "    last_yad_df = whole_log_df.groupby(\"session_id\").tail(1)[[\"session_id\", \"yad_no\"]]\n",
    "\n",
    "    # 最後であることがわかるようにラベル is_last を付与\n",
    "    last_yad_df[\"is_last\"] = 1\n",
    "\n",
    "    # 引数の session - yad の組み合わせとマージして\n",
    "    merged = session_yad_df.merge(last_yad_df, on=[\"session_id\", \"yad_no\"], how=\"left\")\n",
    "\n",
    "    # is_last **ではない** (i.e. is_last is null) データのみに絞る\n",
    "    idx_use = merged[\"is_last\"].isnull()\n",
    "    out_df = session_yad_df[idx_use].reset_index(drop=True)\n",
    "\n",
    "    return out_df\n",
    "\n",
    "\n",
    "test_session_yad = remove_last_yad_id(test_session_yad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_session_yad.to_pickle(f\"{OUTPUT_DIR}/{NOTEBOOK_NAME}_merged_train.pkl\")\n",
    "test_session_yad.to_pickle(f\"{OUTPUT_DIR}/{NOTEBOOK_NAME}_merged_test.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

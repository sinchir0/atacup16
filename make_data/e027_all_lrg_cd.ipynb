{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_NAME = \"e027_make_data_all_lrg_cd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import japanize_matplotlib\n",
    "\n",
    "from contextlib import contextmanager\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import shutil\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# ref: Kaggleコード遺産 https://qiita.com/kaggle_grandmaster-arai-san/items/d59b2fb7142ec7e270a5 \n",
    "class Timer:\n",
    "    def __init__(self, logger=None, format_str=\"{:.3f}[s]\", prefix=None, suffix=None, sep=\" \"):\n",
    "\n",
    "        if prefix: format_str = str(prefix) + sep + format_str\n",
    "        if suffix: format_str = format_str + sep + str(suffix)\n",
    "        self.format_str = format_str\n",
    "        self.logger = logger\n",
    "        self.start = None\n",
    "        self.end = None\n",
    "\n",
    "    @property\n",
    "    def duration(self):\n",
    "        if self.end is None:\n",
    "            return 0\n",
    "        return self.end - self.start\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.end = time()\n",
    "        out_str = self.format_str.format(self.duration)\n",
    "        if self.logger:\n",
    "            self.logger.info(out_str)\n",
    "        else:\n",
    "            print(out_str)\n",
    "\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# 再現性確保!\n",
    "seed_everything(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"../data\"\n",
    "OUTPUT_DIR = f\"../saved_data/{NOTEBOOK_NAME}\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習用のログデータと正解ラベル\n",
    "train_log = pd.read_csv(os.path.join(INPUT_DIR, \"train_log.csv\"))\n",
    "train_session = pd.read_csv(os.path.join(INPUT_DIR, \"train_label.csv\"))\n",
    "\n",
    "# 宿のデータ\n",
    "yado = pd.read_csv(os.path.join(INPUT_DIR, \"yado.csv\"))\n",
    "\n",
    "# テスト期間のログデータ\n",
    "test_log = pd.read_csv(os.path.join(INPUT_DIR, \"test_log.csv\"))\n",
    "test_session = pd.read_csv(os.path.join(INPUT_DIR, \"test_session.csv\"))\n",
    "\n",
    "sample_submission = pd.read_csv(os.path.join(INPUT_DIR, \"sample_submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_log_df = pd.concat([train_log, test_log], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_negative_sample(\n",
    "    log_df: pd.DataFrame, session_df: pd.DataFrame, yado: pd.DataFrame, N: int\n",
    "):\n",
    "    # yad_noとlrg_cdの辞書\n",
    "    yad_no_lrg_cd_dict = dict(zip(yado[\"yad_no\"], yado[\"lrg_cd\"]))\n",
    "    # session_idとyad_noの辞書\n",
    "    session_id_yad_no_dict = (\n",
    "        log_df.groupby(\"session_id\")[\"yad_no\"].apply(list).to_dict()\n",
    "    )\n",
    "    # lrg_cdとyad_noの辞書\n",
    "    lrg_cd_yad_no_dict = yado.groupby(\"lrg_cd\")[\"yad_no\"].apply(list).to_dict()\n",
    "\n",
    "    # logに存在したyad_noを追加\n",
    "    session_df[\"logged_yad_no\"] = session_df[\"session_id\"].map(session_id_yad_no_dict)\n",
    "\n",
    "    # logの最後のyad_noを追加\n",
    "    session_df[\"last_yad_no\"] = session_df[\"logged_yad_no\"].apply(lambda x: x[-1])\n",
    "    # logの最後のyad_noに対するlrg_cdを追加\n",
    "    session_df[\"last_lrg_cd\"] = session_df[\"last_yad_no\"].map(yad_no_lrg_cd_dict)\n",
    "    session_df[\"last_yad_no\"] = session_df[\"logged_yad_no\"].apply(lambda x: x[-1])\n",
    "\n",
    "    # 最後のlogのデータから、同じlrg_cdのyad_noを追加\n",
    "    session_df[\"last_yad_no_lrg_cd\"] = session_df[\"last_yad_no\"].map(yad_no_lrg_cd_dict)\n",
    "\n",
    "    session_df[\"same_lrg_cd_yad_no\"] = session_df[\"last_yad_no_lrg_cd\"].map(\n",
    "        lrg_cd_yad_no_dict\n",
    "    )\n",
    "\n",
    "    # same_lrg_cd_yad_noの中から、logged_yad_noには存在しないyad_noをnegative_sampleとして10件追加\n",
    "    negative_samples = []\n",
    "    for logged_yad_no, same_lrg_cd_yad_no in tqdm(\n",
    "        zip(session_df[\"logged_yad_no\"], session_df[\"same_lrg_cd_yad_no\"]),\n",
    "        total=len(session_df),\n",
    "    ):\n",
    "        same_lrg_cd_yad_no_wo_logged_yad_no = list(\n",
    "            set(same_lrg_cd_yad_no) - set(logged_yad_no)\n",
    "        )\n",
    "        negative_yad_no_10 = random.sample(\n",
    "            same_lrg_cd_yad_no_wo_logged_yad_no,\n",
    "            min(N, len(same_lrg_cd_yad_no_wo_logged_yad_no)),\n",
    "        )\n",
    "        negative_samples.append(negative_yad_no_10)\n",
    "\n",
    "    session_df[\"negative_sample\"] = negative_samples\n",
    "\n",
    "    negative_data = (\n",
    "        session_df[[\"session_id\", \"negative_sample\"]]\n",
    "        .explode(\"negative_sample\")\n",
    "        .rename(columns={\"negative_sample\": \"yad_no\"})\n",
    "    )\n",
    "\n",
    "    negative_data = negative_data.sort_values([\"session_id\", \"yad_no\"])\n",
    "\n",
    "    return negative_data\n",
    "\n",
    "\n",
    "# add_negative_sample(train_log, train_session, yado, N=10)\n",
    "# add_negative_sample(test_log, test_session, yado, N=100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの一番最後に存在するログは必ず正解ではないため、除外する\n",
    "def remove_last_yad_id(log_df: pd.DataFrame, session_df: pd.DataFrame):\n",
    "    # セッション中一番最後の宿の組を作成\n",
    "    last_yad_df = log_df.groupby(\"session_id\").tail(1)[[\"session_id\", \"yad_no\"]]\n",
    "\n",
    "    # 最後であることがわかるようにラベル is_last を付与\n",
    "    last_yad_df[\"is_last\"] = 1\n",
    "\n",
    "    # 引数の session - yad の組み合わせとマージ\n",
    "    merged = session_df.merge(last_yad_df, on=[\"session_id\", \"yad_no\"], how=\"left\")\n",
    "\n",
    "    # is_last **ではない** (i.e. is_last is null) データのみに絞る\n",
    "    idx_use = merged[\"is_last\"].isnull()\n",
    "    session_df = session_df[idx_use].reset_index(drop=True)\n",
    "\n",
    "    return session_df\n",
    "\n",
    "\n",
    "# remove_last_yad_id(log_df=test_log, session_df=test_session_yad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_session_train_yad_df(\n",
    "    log_df: pd.DataFrame, label_df: pd.DataFrame, yado: pd.DataFrame\n",
    "):\n",
    "    # 負例を追加\n",
    "    negative_data = add_negative_sample(log_df, label_df, yado, N=100_000)\n",
    "\n",
    "    # ランダムに付け加えたもの以外・同一ログに出現する宿を候補にいれる\n",
    "    no_dup_train_log = log_df[[\"session_id\", \"yad_no\"]].drop_duplicates()\n",
    "    out_df = pd.concat([no_dup_train_log, negative_data], ignore_index=True)\n",
    "\n",
    "    # 正解のデータを追加\n",
    "    # out_df = pd.concat([label_df, out_df], ignore_index=True)\n",
    "\n",
    "    # 最後の宿は正解になりえないので除外\n",
    "    out_df = remove_last_yad_id(log_df=log_df, session_df=out_df)\n",
    "\n",
    "    # 正解ラベルに含まれているレコードの index を配列で取得して\n",
    "    target_index = pd.merge(\n",
    "        out_df.reset_index(), label_df, on=[\"session_id\", \"yad_no\"], how=\"inner\"\n",
    "    )[\"index\"].values\n",
    "\n",
    "    # 正解Indexに含まれている場合 1 / そうでないと 0 のラベルを作成\n",
    "    out_df[\"reserve\"] = out_df.index.isin(target_index).astype(int)\n",
    "\n",
    "    # 重複を省く\n",
    "    out_df = out_df.drop_duplicates(subset=[\"session_id\", \"yad_no\"], keep=\"first\")\n",
    "\n",
    "    # 見た目を揃えるために session / yad の順番でソートをします\n",
    "    out_df = out_df.sort_values([\"session_id\", \"yad_no\"]).reset_index(drop=True)\n",
    "\n",
    "    # 必要な列に限定\n",
    "    out_df = out_df[[\"session_id\", \"yad_no\", \"reserve\"]]\n",
    "\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ce282ada3142f38778c9c330de878f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/288698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_session_yad = create_session_train_yad_df(\n",
    "    log_df=train_log, label_df=train_session, yado=yado\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_session_test_yad_df(\n",
    "    log_df: pd.DataFrame, session_df: pd.DataFrame, yado: pd.DataFrame\n",
    "):\n",
    "    negative_data = add_negative_sample(\n",
    "        log_df, session_df, yado, N=100_000_000\n",
    "    )  # 無駄に大きい値を入れて、常に全件取るようにする\n",
    "\n",
    "    # ランダムに付け加えたもの以外・同一ログに出現する宿を候補にいれる\n",
    "    no_dup_train_log = log_df[[\"session_id\", \"yad_no\"]].drop_duplicates()\n",
    "    out_df = pd.concat([no_dup_train_log, negative_data], ignore_index=True)\n",
    "\n",
    "    # testデータの一番最後に存在するログは必ず正解ではないため、除外する\n",
    "    out_df = remove_last_yad_id(log_df=log_df, session_df=out_df)\n",
    "\n",
    "    # 重複を省く\n",
    "    out_df = out_df.drop_duplicates(subset=[\"session_id\", \"yad_no\"], keep=\"first\")\n",
    "\n",
    "    # 見た目を揃えるために session / yad の順番でソートをします\n",
    "    out_df = out_df.sort_values([\"session_id\", \"yad_no\"]).reset_index(drop=True)\n",
    "\n",
    "    # 必要な列に限定\n",
    "    out_df = out_df[[\"session_id\", \"yad_no\"]]\n",
    "\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21402eb7b3aa4d44b7e43635748d6bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_session_yad = create_session_test_yad_df(\n",
    "    log_df=test_log, session_df=test_session, yado=yado\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27794931, 3)\n",
      "(14670526, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_session_yad.shape)\n",
    "print(test_session_yad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_session_yad.to_pickle(f\"{OUTPUT_DIR}/{NOTEBOOK_NAME}_merged_train.pkl\")\n",
    "test_session_yad.to_pickle(f\"{OUTPUT_DIR}/{NOTEBOOK_NAME}_merged_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
